---
title: Malware Analysis Part 1 - Using CNN-Based Malware Classification
date: 2026-01-13 13:54:00 +/-TTTT
image:
  path: assets/img/favicons/applsci-11-06446-ag-550.jpg
  class: "img-right"
categories: [CyberSecurity]
tags: [Threat Hunting]
---

# Malware Classification Using Deep Learning

***

### Table of Contents

1. [Introduction](#id-1.-introduction)
2. [Python and Machine Learning Basics](#id-2.-python-and-machine-learning-basics)
3. [The Dataset](#id-3.-the-dataset)
4. [Complete Pipeline: From Data to Trained Model](#id-4.-complete-pipeline-from-data-to-trained-model)
5. [Understanding the Results](#id-5.-understanding-the-results)
6. [Improving the Model](#id-6.-improving-the-model)
7. [Practical Considerations](#id-7.-practical-considerations)
8. [Conclusion](#id-8.-conclusion)
9. [Appendix: Complete Code](#appendix-a-complete-code)
10. [Troubleshooting](#appendix-b-troubleshooting)

***

### 1. Introduction

#### 1.1 The Problem

Malware (malicious software) is software designed to damage systems or steal information. Security researchers need to classify malware into families - groups of malware that behave similarly or come from the same source. This helps understand threats and build defenses.

The traditional way to classify malware is manual analysis. You'd open the malware binary in specialized tools, reverse engineer it to see what it does, watch how it behaves when running, and compare it to known families. This can take hours or even days per sample. When you're dealing with thousands of new malware samples every day, manual analysis doesn't scale.

This is where machine learning can help. If we can teach a computer to recognize patterns that distinguish different malware families, we can automate most of the classification work.

#### 1.2 Why Use Images?

Here's the interesting part - instead of feeding raw binary code to our model, we convert malware binaries into grayscale images. This might sound weird, but there's good reasoning:

1. **Safety:** We're working with images of malware, not actual executable code. You can't accidentally infect your computer with a picture.
2. **Visual patterns:** Malware from the same family often has similar code structure, which shows up as visual patterns in images.
3. **No need to understand assembly:** The model looks at pixel patterns rather than trying to understand machine code.

The conversion is simple. A binary file is just a sequence of bytes (values from 0 to 255). We map each byte to a pixel where the byte value determines the pixel's brightness. Byte value 0 becomes black, 255 becomes white, and everything in between is a shade of gray.

<figure><img src="https://4146235939-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FVsJVX5kOfAZOe1840NhZ%2Fuploads%2FIHzx6Iai5LQBIIDP20EF%2Fimage.png?alt=media&#x26;token=3817f70b-78eb-4f50-836b-709a7c246398" alt="[Figure 1: Binary to image conversion diagram - each byte maps to one pixel]"><figcaption></figcaption></figure>

**Figure 1: Binary to image conversion diagram - each byte maps to one pixel**

#### 1.3 Our Approach

We'll build a classifier using a Convolutional Neural Network (CNN). Don't worry if you haven't heard of CNNs - I'll explain them when we get there. For now, think of it as a type of model that's really good at recognizing patterns in images.

The workflow is:

1. Get a dataset of malware images (already converted from binaries)
2. Split it into training and testing sets
3. Train a CNN to recognize which family each image belongs to
4. Test how accurate our classifier is

***

### 2. Python and Machine Learning Basics

Before we write code, let's talk about the tools we'll use. If you've done some programming but haven't used Python for machine learning, this section will get you up to speed.

#### 2.1 Why Python?

Python has become the standard language for machine learning because:

* **Libraries:** There are well-tested libraries that handle complex math and data processing for you
* **Readable syntax:** Python code is close to plain English, which makes learning easier
* **Community:** Most ML tutorials and research code use Python, so you can find help easily

#### 2.2 The Libraries We'll Use

Think of libraries as toolboxes. Instead of building everything from scratch, we import tools that others have already built and tested.

**NumPy:** Handles arrays and mathematical operations. In ML, you work with lots of numbers organized in arrays (like matrices). NumPy makes this fast and easy.

**pandas:** Works with structured data (like spreadsheets). We'll use it briefly to handle dataset metadata if needed.

**PyTorch:** The main machine learning framework. It handles:

* Building neural networks (defining layers and connections)
* Training models (adjusting weights based on errors)
* Running on GPUs (for speed)

**torchvision:** PyTorch's helper for computer vision (image-related tasks). It includes:

* Common image transformations (resize, normalize, etc.)
* Pre-trained models (models already trained on huge datasets)
* Dataset loaders (efficient ways to feed data to models)

**matplotlib:** Creates plots and visualizations. Useful for seeing data distributions and training progress.

#### 2.3 What is Machine Learning?

Machine learning is about finding patterns in data automatically. Instead of writing explicit rules ("if the file does X, it's malware family Y"), we show the computer many examples and let it figure out the patterns.

The basic idea:

1. Start with a model that makes random guesses
2. Show it training examples with correct answers
3. Measure how wrong the guesses are
4. Adjust the model to reduce errors
5. Repeat thousands of times until it gets good

This process is called *training*. After training, the model should be able to classify new examples it has never seen.

#### 2.4 Why CNNs for Images?

CNNs (Convolutional Neural Networks) are designed specifically for images. Here's the intuition:

When you look at a picture of a cat, you don't analyze every pixel individually. You notice patterns - ears, whiskers, fur texture. CNNs work similarly. They learn to detect small patterns (like edges), then combine these into bigger patterns (like shapes), and finally into high-level features (like "this looks like malware family X").

The key is that CNNs preserve spatial relationships. Nearby pixels are processed together, which makes sense because adjacent bytes in a binary file are often related (they might be part of the same function or data structure).

For our malware images, the CNN might learn to recognize:

* Specific code sequences that appear as visual patterns
* Structures common to certain compilers or packers
* Characteristic padding or data sections

***

### 3. The Dataset

#### 3.1 Dataset Overview

We'll use the *malimg* dataset. It contains 9,339 grayscale images representing 25 different malware families. You can download it from [Kaggle](https://www.kaggle.com/api/v1/datasets/download/ikrambenabd/malimg-original).

Each image is a visualization of a Windows executable (PE file). The dataset is organized into folders where each folder name is the malware family name.

<figure><img src="https://4146235939-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FVsJVX5kOfAZOe1840NhZ%2Fuploads%2FuR07yVN0Y4eBF1GZfrL9%2Fimage.png?alt=media&#x26;token=72c71dca-c796-41d5-aabd-80df9102a407" alt=""><figcaption></figcaption></figure>

**Figure 2: Example malware image showing byte patterns**

#### 3.2 Understanding Class Distribution

Before training, it's important to know if some classes are over-represented. If 90% of our data is from one family, the model might just learn to guess that family every time.

Let's explore the dataset. This code counts how many images are in each family folder:

```python
import os
import matplotlib.pyplot as plt
import seaborn as sns

# Point to where you unzipped the dataset
DATA_BASE_PATH = "./malimg_paper_dataset_imgs/"

# Count images in each family folder
dist = {}
for family_name in os.listdir(DATA_BASE_PATH):
    family_folder = os.path.join(DATA_BASE_PATH, family_name)
    # Count files in this folder
    dist[family_name] = len(os.listdir(family_folder))

# Print what we found
print(f"Total families: {len(dist)}")
print(f"Total images: {sum(dist.values())}")
```

Now let's visualize this:

```python
# Prepare data for plotting
families = list(dist.keys())
counts = list(dist.values())

# Create the plot
plt.figure(figsize=(10, 8))
sns.barplot(y=families, x=counts, orient='h')
plt.title("Malware Family Distribution")
plt.xlabel("Number of Samples")
plt.ylabel("Malware Family")
plt.tight_layout()
plt.show()
```

<figure><img src="https://4146235939-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FVsJVX5kOfAZOe1840NhZ%2Fuploads%2Fp8aVOYmiZcZEY3wAdd4K%2Fimage.png?alt=media&#x26;token=69ab26d6-cdf4-46db-8d3c-f398094a2696" alt=""><figcaption></figcaption></figure>

**Figure 3: Class distribution bar chart - Allaple.A and Allaple.L have the most samples**

From the plot, we can see the dataset is imbalanced. Some families have thousands of samples while others have just a few hundred. This is common in real-world datasets. Our model might perform better on families with more training examples.

#### 3.3 Visual Patterns in Malware Families

Let's look at two samples from the same family to see if they really share visual patterns:

<figure><img src="https://4146235939-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FVsJVX5kOfAZOe1840NhZ%2Fuploads%2FG53cQt2BC21tmFD3JCZF%2Fimage.png?alt=media&#x26;token=a1cfa9c6-2123-44f3-8210-71bc3fcad78d" alt=""><figcaption></figcaption></figure>

<figure><img src="https://4146235939-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FVsJVX5kOfAZOe1840NhZ%2Fuploads%2Fp3hq3oFELnPw6Ahu2jyt%2Fimage.png?alt=media&#x26;token=e936b3d6-b668-4432-9c3b-1da5b5f743ea" alt=""><figcaption></figcaption></figure>

**Figure 4: Two FakeRean samples side by side showing similar vertical striping patterns**

You can see both images have similar structures. These patterns come from shared code, data layouts, or packing methods used by this malware family. The CNN will learn to recognize these patterns.

***

### 4. Complete Pipeline: From Data to Trained Model

Now let's build the complete pipeline. This is one continuous program that goes from loading data to training a classifier. I'll explain each part as we go.

#### 4.1 Setup and Imports

First, import everything we need:

```python
import os
import time
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import transforms, datasets, models
import matplotlib.pyplot as plt

# Check if GPU is available - training is much faster on GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")
```

The `device` variable tells PyTorch whether to use a GPU or CPU. If you have a NVIDIA GPU with CUDA installed, training will be much faster.

#### 4.2 Step 1: Preparing the Data

First, we need to split our dataset into training and testing sets. We'll use 80% for training and 20% for testing.

```python
# Install split-folders if you haven't: pip install split-folders
import splitfolders

# Where your original dataset is
INPUT_PATH = "./malimg_paper_dataset_imgs/"
# Where to save the split data
OUTPUT_PATH = "./data_split/"

# Split: 80% train, 0% validation, 20% test
# We're not using validation here to keep it simple
splitfolders.ratio(
    input=INPUT_PATH, 
    output=OUTPUT_PATH,
    seed=42,  # Random seed for reproducibility
    ratio=(0.8, 0, 0.2)
)
print("Dataset split complete!")
```

Why split the data? If we test on the same data we trained on, the model might just memorize the training examples. Testing on unseen data tells us if the model actually learned patterns or just memorized.

#### 4.3 Step 2: Image Preprocessing

CNNs need consistent input. All images must be the same size, and pixel values should be normalized.

```python
# Define how we'll preprocess images
transform = transforms.Compose([
    # Resize all images to 75x75 pixels
    # Why 75x75? Smaller = faster training, but we lose some detail
    # This is a balance between speed and information
    transforms.Resize((75, 75)),
    
    # Convert PIL Image to PyTorch tensor (multi-dimensional array)
    # Also scales pixel values from 0-255 to 0-1
    transforms.ToTensor(),
    
    # Normalize using ImageNet statistics
    # These values are standard for models pre-trained on ImageNet
    # Normalization helps the model train more stably
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],  # Average RGB values
        std=[0.229, 0.224, 0.225]     # Standard deviations
    )
])
```

**Why normalize?** Neural networks train better when inputs are in a consistent range. Without normalization, some features might dominate just because they have larger numbers, not because they're more important.

**Why these specific mean/std values?** We're using a pre-trained model (explained later) that was trained with these normalization values. Using the same preprocessing ensures consistency.

Now let's load the datasets:

```python
# Load training data
# ImageFolder expects data organized as: root/class_name/image.png
train_dataset = datasets.ImageFolder(
    root=os.path.join(OUTPUT_PATH, "train"),
    transform=transform
)

# Load test data
test_dataset = datasets.ImageFolder(
    root=os.path.join(OUTPUT_PATH, "test"),
    transform=transform
)

# How many classes do we have?
num_classes = len(train_dataset.classes)
print(f"Number of malware families: {num_classes}")
print(f"Training samples: {len(train_dataset)}")
print(f"Test samples: {len(test_dataset)}")
```

#### 4.4 Step 3: Creating Data Loaders

Data loaders handle batching and shuffling. Instead of feeding one image at a time, we feed batches (groups of images). This is more efficient and helps the model learn better.

```python
# Batch size: how many images to process together
# Larger batches = faster but need more memory
# 32-128 is typical for image classification
BATCH_SIZE = 64

# Create loader for training data
train_loader = DataLoader(
    train_dataset,
    batch_size=BATCH_SIZE,
    shuffle=True,        # Randomize order each epoch
    num_workers=2,       # Parallel data loading (faster)
    pin_memory=True      # Faster GPU transfer
)

# Create loader for test data
test_loader = DataLoader(
    test_dataset,
    batch_size=BATCH_SIZE,
    shuffle=False,       # No need to shuffle test data
    num_workers=2,
    pin_memory=True
)
```

**Why shuffle training data?** If we always see malware families in the same order, the model might learn order-dependent patterns instead of real distinguishing features. Shuffling prevents this.

**Why not shuffle test data?** Order doesn't matter for testing - we just want consistent results.

Let's check what a batch looks like:

```python
# Get one batch
images, labels = next(iter(train_loader))
print(f"Batch shape: {images.shape}")  # Should be [batch_size, 3, 75, 75]
print(f"Labels shape: {labels.shape}") # Should be [batch_size]

# Note: images has 3 channels even though our images are grayscale
# This is because transforms.ToTensor() converts grayscale to RGB format
# (duplicating the single channel three times) to match the pre-trained model's expectations
```

#### 4.5 Step 4: Building the Model

Now the interesting part. We'll use *transfer learning* - starting with a model pre-trained on a huge dataset (ImageNet) and adapting it for our task.

**Why transfer learning?** Training a CNN from scratch requires millions of images and days of computation. By starting with a pre-trained model, we leverage knowledge it already learned about recognizing patterns in images.

```python
class MalwareClassifier(nn.Module):
    def __init__(self, num_classes):
        super(MalwareClassifier, self).__init__()
        
        # Load ResNet50 with pre-trained weights
        # ResNet50 is a 50-layer CNN that's proven to work well
        self.resnet = models.resnet50(weights='DEFAULT')
        
        # Freeze all layers except the last one
        # "Freezing" means these weights won't change during training
        # Why? These layers already learned useful low-level features
        # (edges, textures, shapes) from ImageNet
        # Only the final layer needs to adapt to malware classification
        for param in self.resnet.parameters():
            param.requires_grad = False
        
        # Replace the final layer
        # Original ResNet50 outputs 1000 classes (ImageNet has 1000 categories)
        # We need to output num_classes (25 malware families)
        num_features = self.resnet.fc.in_features  # Usually 2048
        
        self.resnet.fc = nn.Sequential(
            nn.Linear(num_features, 512),  # Intermediate layer
            nn.ReLU(),                      # Activation function
            nn.Dropout(0.3),                # Randomly drop 30% of connections
                                            # This prevents overfitting
            nn.Linear(512, num_classes)     # Final output layer
        )

    def forward(self, x):
        # This defines how data flows through the model
        return self.resnet(x)

# Create the model
model = MalwareClassifier(num_classes)
model = model.to(device)  # Move model to GPU if available

print(f"Model created with {num_classes} output classes")
```

**Why freeze layers?** Training all 50 layers would take much longer and might actually perform worse with our small dataset. The early layers learn generic features (edges, textures) that are useful for any image task. We only need to teach the final layers what patterns identify each malware family.

**What's Dropout?** During training, dropout randomly "turns off" some neurons. This forces the network to learn robust features rather than memorizing specific examples.

#### 4.6 Step 5: Training Setup

Before training, we define:

* **Loss function:** Measures how wrong the model's predictions are
* **Optimizer:** Algorithm that adjusts weights to reduce loss
* **Learning rate:** How big each adjustment step should be

```python
# Loss function for multi-class classification
# CrossEntropyLoss combines softmax and negative log-likelihood
# It's standard for classification tasks
criterion = nn.CrossEntropyLoss()

# Optimizer: Adam is usually a good default choice
# It adapts the learning rate automatically during training
optimizer = optim.Adam(
    model.resnet.fc.parameters(),  # Only train the final layer
    lr=0.001  # Learning rate - how fast we update weights
              # 0.001 is a common starting point
)

# Learning rate scheduler (optional but helpful)
# Reduces learning rate when progress plateaus
# This helps fine-tune the model in later epochs
scheduler = optim.lr_scheduler.ReduceLROnPlateau(
    optimizer,
    mode='max',      # We want to maximize accuracy
    factor=0.5,      # Reduce LR by half when needed
    patience=2,      # Wait 2 epochs before reducing
    verbose=True
)
```

**What's a learning rate?** If loss is a valley and we want to reach the bottom, learning rate is our step size. Too large and we overshoot. Too small and training takes forever. We start at 0.001 and reduce it if we stop improving.

#### 4.7 Step 6: The Training Loop

This is where the actual learning happens. For each epoch (one pass through all training data):

1. Feed batches of images to the model
2. Calculate how wrong the predictions are (loss)
3. Adjust weights to reduce the error (backpropagation)
4. Repeat

```python
def train_one_epoch(model, train_loader, criterion, optimizer, device):
    """Train for one epoch and return average loss and accuracy"""
    model.train()  # Set model to training mode (enables dropout, etc.)
    
    running_loss = 0.0
    correct = 0
    total = 0
    
    for batch_idx, (images, labels) in enumerate(train_loader):
        # Move data to GPU if available
        images = images.to(device)
        labels = labels.to(device)
        
        # Zero the gradients from previous batch
        # (PyTorch accumulates gradients by default)
        optimizer.zero_grad()
        
        # Forward pass: get model predictions
        outputs = model(images)
        
        # Calculate loss (how wrong are we?)
        loss = criterion(outputs, labels)
        
        # Backward pass: compute gradients
        # This calculates how much each weight contributed to the error
        loss.backward()
        
        # Update weights based on gradients
        optimizer.step()
        
        # Track statistics
        running_loss += loss.item()
        _, predicted = outputs.max(1)  # Get class with highest score
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()
        
        # Print progress every 20 batches
        if (batch_idx + 1) % 20 == 0:
            print(f"  Batch {batch_idx+1}/{len(train_loader)}, "
                  f"Loss: {loss.item():.4f}")
    
    # Calculate averages for the epoch
    avg_loss = running_loss / len(train_loader)
    accuracy = 100.0 * correct / total
    
    return avg_loss, accuracy
```

**What's backpropagation?** It's the algorithm that figures out how to adjust each weight. Starting from the output error, it works backwards through the network calculating each weight's contribution to the mistake.

#### 4.8 Step 7: Evaluation Function

We need to check how well the model performs on test data:

```python
def evaluate(model, test_loader, criterion, device):
    """Evaluate model on test data"""
    model.eval()  # Set to evaluation mode (disables dropout)
    
    running_loss = 0.0
    correct = 0
    total = 0
    
    # Don't calculate gradients during testing (saves memory and time)
    with torch.no_grad():
        for images, labels in test_loader:
            images = images.to(device)
            labels = labels.to(device)
            
            # Get predictions
            outputs = model(images)
            loss = criterion(outputs, labels)
            
            # Track statistics
            running_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()
    
    avg_loss = running_loss / len(test_loader)
    accuracy = 100.0 * correct / total
    
    return avg_loss, accuracy
```

#### 4.9 Step 8: Main Training Loop

Now we put it all together:

```python
# Training parameters
NUM_EPOCHS = 10  # How many times to go through the entire dataset

# Track progress
train_losses = []
train_accuracies = []
test_losses = []
test_accuracies = []

print("Starting training...")
best_test_acc = 0.0

for epoch in range(NUM_EPOCHS):
    print(f"\nEpoch {epoch+1}/{NUM_EPOCHS}")
    print("-" * 50)
    
    # Train for one epoch
    train_loss, train_acc = train_one_epoch(
        model, train_loader, criterion, optimizer, device
    )
    
    # Evaluate on test set
    test_loss, test_acc = evaluate(
        model, test_loader, criterion, device
    )
    
    # Update learning rate based on test accuracy
    scheduler.step(test_acc)
    
    # Save statistics
    train_losses.append(train_loss)
    train_accuracies.append(train_acc)
    test_losses.append(test_loss)
    test_accuracies.append(test_acc)
    
    # Print epoch summary
    print(f"\nEpoch {epoch+1} Summary:")
    print(f"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%")
    print(f"  Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%")
    
    # Save best model
    if test_acc > best_test_acc:
        best_test_acc = test_acc
        torch.save(model.state_dict(), 'best_malware_classifier.pth')
        print(f"  *** New best test accuracy! Model saved. ***")

print("\nTraining complete!")
print(f"Best test accuracy: {best_test_acc:.2f}%")
```

**Why save the best model?** Test accuracy might fluctuate. We save the version that performed best so we don't lose it if later epochs perform worse.

#### 4.10 Step 9: Visualizing Training Progress

Let's see how the model improved over time:

```python
# Create two plots side by side
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))

# Plot 1: Loss over time
ax1.plot(train_losses, label='Training Loss', marker='o')
ax1.plot(test_losses, label='Test Loss', marker='s')
ax1.set_xlabel('Epoch')
ax1.set_ylabel('Loss')
ax1.set_title('Loss Over Time')
ax1.legend()
ax1.grid(True, alpha=0.3)

# Plot 2: Accuracy over time
ax2.plot(train_accuracies, label='Training Accuracy', marker='o')
ax2.plot(test_accuracies, label='Test Accuracy', marker='s')
ax2.set_xlabel('Epoch')
ax2.set_ylabel('Accuracy (%)')
ax2.set_title('Accuracy Over Time')
ax2.legend()
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('training_progress.png', dpi=150, bbox_inches='tight')
plt.show()

print("Training curves saved as 'training_progress.png'")
```

<figure><img src="https://4146235939-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FVsJVX5kOfAZOe1840NhZ%2Fuploads%2FwvOWOTJhOee5pkhTIwBd%2Fimage.png?alt=media&#x26;token=1794138a-e96a-4c7d-8ef2-edd24dd79811" alt=""><figcaption></figcaption></figure>

**Figure 5: Training accuracy graph showing steady increase over epochs**

**What to look for:**

* Training accuracy should increase (loss should decrease)
* If test accuracy is much lower than training, we're overfitting
* If both are low, the model isn't learning well (might need more training or a different architecture)

#### 4.11 Step 10: Testing the Model

Let's test our trained model on a few specific examples:

```python
def predict_sample(model, image_path, transform, device, class_names):
    """Predict the malware family for a single image"""
    from PIL import Image
    
    model.eval()
    
    # Load and preprocess the image
    image = Image.open(image_path).convert('RGB')
    image_tensor = transform(image).unsqueeze(0)  # Add batch dimension
    image_tensor = image_tensor.to(device)
    
    # Get prediction
    with torch.no_grad():
        output = model(image_tensor)
        probabilities = torch.nn.functional.softmax(output, dim=1)
        confidence, predicted_class = probabilities.max(1)
    
    predicted_family = class_names[predicted_class.item()]
    confidence_pct = confidence.item() * 100
    
    return predicted_family, confidence_pct

# Get class names from the dataset
class_names = train_dataset.classes

# Test on a random image from test set
import random
test_image_path = random.choice(test_dataset.imgs)[0]
actual_family = os.path.basename(os.path.dirname(test_image_path))

predicted_family, confidence = predict_sample(
    model, test_image_path, transform, device, class_names
)

print(f"\nTest Image: {test_image_path}")
print(f"Actual Family: {actual_family}")
print(f"Predicted Family: {predicted_family}")
print(f"Confidence: {confidence:.2f}%")
print(f"Correct: {actual_family == predicted_family}")
```

***

### 5. Understanding the Results

#### 5.1 Typical Performance

With this setup, you should see:

* Training accuracy reaching 95-97% after 10 epochs
* Test accuracy around 85-90%
* The gap between training and test accuracy indicates some overfitting, which is normal with a small dataset

#### 5.2 What Each Metric Means

When evaluating classifiers, we look at several metrics:

**Accuracy:** Percentage of correct predictions

Accuracy = (Correct Predictions) / (Total Predictions)

This is intuitive but can be misleading with imbalanced data. If 95% of samples are from one family, you could get 95% accuracy just by always guessing that family.

**Precision:** Of all predictions for a specific family, how many were correct?

Precision = (True Positives) / (True Positives + False Positives)

High precision means when the model says "this is family X", it's usually right.

**Recall:** Of all actual samples from a family, how many did we correctly identify?

Recall = (True Positives) / (True Positives + False Negatives)

High recall means we catch most instances of each family.

**F1-Score:** Harmonic mean of precision and recall

F1 = 2 × (Precision × Recall) / (Precision + Recall)

F1-score is useful when you care about both false positives and false negatives equally.

#### 5.3 Computing Detailed Metrics

Let's calculate per-class metrics:

```python
from sklearn.metrics import classification_report, confusion_matrix
import numpy as np

def detailed_evaluation(model, test_loader, device, class_names):
    """Get detailed per-class metrics"""
    model.eval()
    
    all_predictions = []
    all_labels = []
    
    with torch.no_grad():
        for images, labels in test_loader:
            images = images.to(device)
            outputs = model(images)
            _, predicted = outputs.max(1)
            
            all_predictions.extend(predicted.cpu().numpy())
            all_labels.extend(labels.numpy())
    
    # Generate classification report
    print("\nDetailed Classification Report:")
    print("=" * 70)
    report = classification_report(
        all_labels, 
        all_predictions, 
        target_names=class_names,
        digits=3
    )
    print(report)
    
    # Confusion matrix
    cm = confusion_matrix(all_labels, all_predictions)
    return cm

# Run detailed evaluation
cm = detailed_evaluation(model, test_loader, device, class_names)

# Find which families the model struggles with
print("\nFamilies with lowest accuracy:")
class_accuracies = cm.diagonal() / cm.sum(axis=1)
worst_families = np.argsort(class_accuracies)[:5]

for idx in worst_families:
    family = class_names[idx]
    acc = class_accuracies[idx] * 100
    samples = cm.sum(axis=1)[idx]
    print(f"  {family}: {acc:.1f}% ({samples} test samples)")
```

#### 5.4 Why Some Families Perform Poorly

You'll notice some families have lower accuracy. Common reasons:

1. **Small sample size:** Families with few training examples are harder to learn
2. **Visual similarity:** Some families might look very similar to each other
3. **Class imbalance:** The model sees more examples from large families, so it learns those better

***

### 6. Improving the Model

#### 6.1 Things You Can Try

If you want better performance, here are some approaches:

**1. Unfreeze more layers**

```python
# Instead of freezing everything, only freeze early layers
for name, param in model.resnet.named_parameters():
    if "layer4" not in name and "fc" not in name:
        param.requires_grad = False
    else:
        param.requires_grad = True
```

This lets the model fine-tune more, but training takes longer.

**2. Use larger images**

```python
# Change from 75x75 to 224x224 (what ResNet was originally trained on)
transforms.Resize((224, 224))
```

More detail helps, but slower training and higher memory usage.

**3. Data augmentation**

```python
# Add random transformations to increase effective dataset size
train_transform = transforms.Compose([
    transforms.Resize((75, 75)),
    transforms.RandomHorizontalFlip(),  # Flip images randomly
    transforms.RandomRotation(10),      # Slight rotations
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                         std=[0.229, 0.224, 0.225])
])
```

This creates variations of training images, helping the model generalize.

**4. Balance the dataset**

```python
from torch.utils.data import WeightedRandomSampler

# Calculate class weights (inverse of frequency)
class_counts = [len(os.listdir(os.path.join(OUTPUT_PATH, "train", cls))) 
                for cls in train_dataset.classes]
class_weights = 1.0 / torch.tensor(class_counts, dtype=torch.float)

# Assign weight to each sample
sample_weights = [class_weights[label] for _, label in train_dataset]

# Create sampler
sampler = WeightedRandomSampler(
    weights=sample_weights,
    num_samples=len(sample_weights),
    replacement=True
)

# Use in DataLoader
train_loader = DataLoader(
    train_dataset,
    batch_size=BATCH_SIZE,
    sampler=sampler,  # Instead of shuffle=True
    num_workers=2
)
```

This ensures the model sees each class equally often, not just the big ones.

**5. Train longer**

```python
NUM_EPOCHS = 25  # Instead of 10
```

More epochs can help, but watch for overfitting (when test accuracy stops improving while training accuracy keeps rising).

#### 6.2 Hyperparameter Tuning

Key hyperparameters you can adjust:

| Parameter         | Effect                  | Typical Range |
| ----------------- | ----------------------- | ------------- |
| Learning rate     | Speed of learning       | 0.0001 - 0.01 |
| Batch size        | Memory/speed tradeoff   | 16 - 256      |
| Dropout rate      | Regularization strength | 0.1 - 0.5     |
| Hidden layer size | Model capacity          | 256 - 2048    |
| Image size        | Detail vs speed         | 64 - 224      |

***

### 7. Practical Considerations

#### 7.1 Real-World Deployment

If you wanted to use this in production:

**1. Save the model properly**

```python
# Save entire model
torch.save({
    'model_state_dict': model.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    'class_names': class_names,
    'best_accuracy': best_test_acc,
}, 'malware_classifier_full.pth')

# Load later
checkpoint = torch.load('malware_classifier_full.pth')
model.load_state_dict(checkpoint['model_state_dict'])
class_names = checkpoint['class_names']
```

**2. Create a simple API**

```python
def classify_malware_file(binary_path, model, transform, device):
    """
    Convert a binary file to image and classify it
    """
    # Read binary file
    with open(binary_path, 'rb') as f:
        binary_data = f.read()
    
    # Convert to image (simplified version)
    import numpy as np
    from PIL import Image
    
    # Convert bytes to numpy array
    byte_array = np.frombuffer(binary_data, dtype=np.uint8)
    
    # Determine image dimensions (make it roughly square)
    width = int(np.sqrt(len(byte_array)))
    height = (len(byte_array) // width) + 1
    
    # Pad if necessary
    pad_size = (width * height) - len(byte_array)
    byte_array = np.pad(byte_array, (0, pad_size), 'constant')
    
    # Reshape to image
    img_array = byte_array.reshape((height, width))
    img = Image.fromarray(img_array, mode='L')  # L = grayscale
    
    # Convert to RGB (our model expects 3 channels)
    img_rgb = img.convert('RGB')
    
    # Classify
    return predict_sample(model, img_rgb, transform, device, class_names)
```

#### 7.2 Limitations

Be aware of what this approach can't do:

1. **New families:** The model only knows the 25 families it trained on. New malware families will be misclassified as one of these 25.
2. **Obfuscation:** If malware authors pack or encrypt their code, the visual patterns change.
3. **Not a complete solution:** This should be part of a larger security pipeline, not the only analysis tool.

#### 7.3 Ethical Considerations

When working with malware:

* Only analyze malware in isolated environments
* Don't distribute malware samples without proper safeguards
* Be aware of legal restrictions in your jurisdiction
* Use findings responsibly for defense, not attack

***

### 8. Conclusion

#### 8.1 What We Built

We created a complete malware classification pipeline:

1. Loaded and split a dataset of malware images
2. Preprocessed images for CNN input
3. Built a classifier using transfer learning (ResNet50)
4. Trained it to distinguish 25 malware families
5. Evaluated performance with multiple metrics

#### 8.2 Key Takeaways

**Transfer learning is powerful:** Instead of training from scratch, we leveraged a pre-trained model and adapted it. This saved days of computation.

**Data quality matters:** The imbalanced dataset affects performance. Some families are learned much better than others.

**Images work for malware:** Converting binaries to images preserves structure and makes patterns visible to CNNs.

**It's practical:** The entire pipeline runs in under 10 minutes on a decent GPU. Fast enough for practical use.

#### 8.3 Next Steps

To go further:

1. Try different CNN architectures (EfficientNet, DenseNet)
2. Implement the improvements suggested in Section 6
3. Collect more balanced training data
4. Explore ensemble methods (combining multiple models)
5. Study which visual patterns the model learns (using techniques like Grad-CAM)

#### 8.4 Final Thoughts

Machine learning for malware analysis is an active research area. This project shows one approach - converting binaries to images. Other methods work directly with binary code, API calls, or behavior logs. Each has tradeoffs.

The key insight is that ML can automate pattern recognition at a scale impossible for humans. While it won't replace security experts, it can handle the initial triage of thousands of samples, letting experts focus on the truly novel threats.

The code we wrote here is a foundation. With the concepts you've learned - data loading, preprocessing, transfer learning, training loops, and evaluation - you can apply similar approaches to other problems. The patterns are the same whether you're classifying malware, medical images, or anything else.

***

### Appendix A: Complete Code

For reference, here's the entire pipeline in one file:

```python
"""
Malware Classification using CNN
Complete pipeline from data loading to evaluation
"""

import os
import time
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import transforms, datasets, models
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report
import splitfolders

# Configuration
INPUT_PATH = "./malimg_paper_dataset_imgs/"
OUTPUT_PATH = "./data_split/"
BATCH_SIZE = 64
NUM_EPOCHS = 10
LEARNING_RATE = 0.001

# Check device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Step 1: Split dataset
print("Splitting dataset...")
if not os.path.exists(OUTPUT_PATH):
    splitfolders.ratio(INPUT_PATH, output=OUTPUT_PATH, 
                       seed=42, ratio=(0.8, 0, 0.2))

# Step 2: Define preprocessing
transform = transforms.Compose([
    transforms.Resize((75, 75)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                         std=[0.229, 0.224, 0.225])
])

# Step 3: Load datasets
train_dataset = datasets.ImageFolder(
    root=os.path.join(OUTPUT_PATH, "train"),
    transform=transform
)
test_dataset = datasets.ImageFolder(
    root=os.path.join(OUTPUT_PATH, "test"),
    transform=transform
)

num_classes = len(train_dataset.classes)
print(f"Classes: {num_classes}, Train: {len(train_dataset)}, "
      f"Test: {len(test_dataset)}")

# Step 4: Create data loaders
train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,
                          shuffle=True, num_workers=2)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE,
                         shuffle=False, num_workers=2)

# Step 5: Define model
class MalwareClassifier(nn.Module):
    def __init__(self, num_classes):
        super(MalwareClassifier, self).__init__()
        self.resnet = models.resnet50(weights='DEFAULT')
        for param in self.resnet.parameters():
            param.requires_grad = False
        num_features = self.resnet.fc.in_features
        self.resnet.fc = nn.Sequential(
            nn.Linear(num_features, 512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, num_classes)
        )
    
    def forward(self, x):
        return self.resnet(x)

model = MalwareClassifier(num_classes).to(device)

# Step 6: Setup training
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.resnet.fc.parameters(), lr=LEARNING_RATE)
scheduler = optim.lr_scheduler.ReduceLROnPlateau(
    optimizer, mode='max', factor=0.5, patience=2, verbose=True
)

# Step 7: Training functions
def train_epoch(model, loader, criterion, optimizer, device):
    model.train()
    running_loss, correct, total = 0.0, 0, 0
    
    for images, labels in loader:
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        
        running_loss += loss.item()
        _, predicted = outputs.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()
    
    return running_loss / len(loader), 100.0 * correct / total

def evaluate(model, loader, criterion, device):
    model.eval()
    running_loss, correct, total = 0.0, 0, 0
    
    with torch.no_grad():
        for images, labels in loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            running_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()
    
    return running_loss / len(loader), 100.0 * correct / total

# Step 8: Training loop
train_accs, test_accs = [], []
best_acc = 0.0

print("\nStarting training...")
for epoch in range(NUM_EPOCHS):
    train_loss, train_acc = train_epoch(
        model, train_loader, criterion, optimizer, device
    )
    test_loss, test_acc = evaluate(
        model, test_loader, criterion, device
    )
    scheduler.step(test_acc)
    
    train_accs.append(train_acc)
    test_accs.append(test_acc)
    
    print(f"Epoch {epoch+1}/{NUM_EPOCHS}: "
          f"Train Acc: {train_acc:.2f}%, Test Acc: {test_acc:.2f}%")
    
    if test_acc > best_acc:
        best_acc = test_acc
        torch.save(model.state_dict(), 'best_model.pth')

print(f"\nBest test accuracy: {best_acc:.2f}%")

# Step 9: Plot results
plt.figure(figsize=(10, 5))
plt.plot(train_accs, label='Train', marker='o')
plt.plot(test_accs, label='Test', marker='s')
plt.xlabel('Epoch')
plt.ylabel('Accuracy (%)')
plt.title('Training Progress')
plt.legend()
plt.grid(True, alpha=0.3)
plt.savefig('training_curve.png', dpi=150, bbox_inches='tight')
plt.show()

print("Training complete!")
```

***

### Appendix B: Troubleshooting

Common issues and solutions:

#### B.1 Out of Memory Error

**Problem:** GPU runs out of memory during training.

**Solutions:**

```python
# Reduce batch size
BATCH_SIZE = 32  # or even 16

# Use smaller images
transforms.Resize((50, 50))  # instead of 75x75

# Use mixed precision training (advanced)
from torch.cuda.amp import autocast, GradScaler
scaler = GradScaler()
```

#### B.2 Slow Training

**Problem:** Training takes too long.

**Solutions:**

* Make sure you're using GPU: check `device` variable
* Increase batch size if memory allows
* Reduce image size
* Use fewer epochs for experimentation

#### B.3 Poor Accuracy

**Problem:** Model accuracy is low even after many epochs.

**Solutions:**

```python
# Try lower learning rate
LEARNING_RATE = 0.0001

# Unfreeze more layers
for param in model.resnet.layer4.parameters():
    param.requires_grad = True

# Use data augmentation (see Section 6.1)
```

#### B.4 Model Not Improving

**Problem:** Loss stops decreasing after a few epochs.

**Check:**

* Is the learning rate too low? Try 0.001
* Is the model too simple? Try unfreezing more layers
* Is data shuffled? Check `shuffle=True` in train loader

***

### References

#### Dataset

* Malimg Dataset: [Kaggle Download](https://www.kaggle.com/api/v1/datasets/download/ikrambenabd/malimg-original)
* Original Paper: Nataraj et al., "Malware Images: Visualization and Automatic Classification"

#### Deep Learning Resources

* PyTorch Documentation: [pytorch.org](https://pytorch.org/docs/)
* ResNet Paper: He et al., "Deep Residual Learning for Image Recognition" (2015)
* Transfer Learning Guide: [PyTorch Tutorials](https://pytorch.org/tutorials/)

#### Malware Analysis

* Malpedia: [malpedia.caad.fkie.fraunhofer.de](https://malpedia.caad.fkie.fraunhofer.de/)
* VirusTotal: Online malware scanning service


**Communities**:
- [/r/Malware](https://www.reddit.com/r/Malware/)
- [MalwareTech](https://www.malwaretech.com/)
- [Malware Traffic Analysis](https://www.malware-traffic-analysis.net/)
- [Any.run community](https://any.run/malware-trends/)

***

**Happy Hacking!**


